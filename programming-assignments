# ðŸ’» Programming Assignments

## PA 1: Is Python Fast or Slow?
- **Info about the project:** This project compares the performance of native Python code versus using the NumPy external library for array multiplications. By testing 1D and 2D arrays of different sizes, it highlights the efficiency gains provided by specialized libraries like NumPy, especially when working with large datasets.
- **Score:** 79.17/100 (79.17%)
- **Report:** [View Report PDF](./project_reports/Is_Python_Fast_or_Slow.pdf)
- **Code:** [View Code](./pa1_code/Group_C_programming_assignment1.ipynb)

## PA 2: Agents
- **Info about the project:** This project evaluates the performance of a vacuum agent in different environments, comparing agents that either keep track of their previous states or operate without memory. Through multiple tests measuring steps taken, dirt cleaned, and efficiency, the study explores how memory impacts the agentâ€™s ability to clean environments with and without obstacles.
- **Score:** 70.83/100 (70.83%)
- **Report:** [View Report PDF](./project_reports/Agents_and_Task_Management.pdf)
- **GitHub Repository and Instructions:** [Agents-and-Task-Management](https://github.com/Dahyna-Martinez/Agents-and-Task-Management)  
  _(See the README.md for project-specific instructions.)_

## PA 3: Search
- **Info about the project:** This project evaluates the performance of search algorithms applied to two problems: pathfinding in a two-dimensional obstacle environment and the Missionaries and Cannibals river-crossing problem. By testing A* Search and Greedy Best-First Search for pathfinding, and BFS and DFS for the river crossing, it compares algorithm efficiency based on steps taken, solution optimality, and ability to handle constraints. The analysis highlights how different search strategies impact performance in environments with varying complexity and rules.
- **Score:** 100/100 (100%)
- **Report:** [View Report PDF](./project_reports/Search_Algorithms.pdf)
- **GitHub Repository and Instructions:** [Search-Algorithms](https://github.com/Dahyna-Martinez/Agents-and-Task-Management)  
  _(See the README.md for project-specific instructions.)_

## PA 4: Hill Climbing Applications and Simulated Annealing
- **Info about the project:** This project evaluates the performance of various hill climbing algorithms by solving randomly generated instances of the 8 Puzzle and 8 Queens problems. It tests Steepest-Ascent Hill Climbing, First-Choice Hill Climbing, Random Restart Hill Climbing, and Simulated Annealing. By tracking metrics such as success rate, search cost, and efficiency, it analyzes how different local search strategies perform depending on the structure and complexity of the problem space, and how problem characteristics influence algorithm effectiveness.
- **Score:** 92.86/100 (92.86%)
- **Report:** [View Report PDF](./project_reports/Hill_Climbing_Applications_and_Simulated_Annealing.pdf)
- **GitHub Repository and Instructions:** [Hill-Climbing-Applications-and-Simulated-Annealing](https://github.com/Dahyna-Martinez/Agents-and-Task-Management)  
  _(See the README.md for project-specific instructions.)_

## PA 5: Adversarial Search
- **Info about the project:** This project develops a digital Puerto Rican Dominoes game featuring human and AI players competing against each other. The AI uses Monte Carlo Simulation to evaluate possible moves by running random simulations and selecting the play with the highest estimated success rate. Multiple game modes are supported, including team-based and free-for-all setups, and the project explores how adversarial search strategies can be applied to complex, stochastic, and partially observable environments like Dominoes.
- **Score:** 100/100 (100%)
- **Report:** [View Report PDF](./project_reports/Adversarial_Search.pdf)
- **GitHub Repository and Instructions:** [DominosAI](https://github.com/JanPerez35/DominosAI.git)  
  _(See the README.md for project-specific instructions.)_

## PA 6: Constraint satisfaction problems (CSP)
- **Info about the project:** This project implements and compares four constraint satisfaction algorithms including Backtracking, Min Conflicts, AC3 with Backtracking, and Forward Checking by applying them to the Zebra Puzzle. It investigates how each algorithm processes variables, domains, and constraints to construct valid solutions. By modeling the puzzle as a structured constraint satisfaction problem, the project analyzes how inference techniques and search strategies influence performance in solving tightly constrained logic problems.
- **Score:** 100/100 (100%)
- **Report:** [View Report PDF](./project_reports/CSP_Reports.pdf)
- **GitHub Repository and Instructions:** [CSP Algorithms](https://github.com/Dahyna-Martinez/Agents-and-Task-Management) 
  _(See the README.md for project-specific instructions.)_

  ---

## Reflection
- The programming assignments were fun, but some were also challenging. One of the biggest difficulties was understanding what each problem was really asking and figuring out how to translate that into code. The assignment I struggled with the most was PA 4, especially implementing the Simulated Annealing algorithm for the 8 Puzzle and 8 Queens problems. On the other hand, I really enjoyed PA 3. It was rewarding to keep improving the pathfinding grid and observe how each algorithm reached the goal. Overall, these assignments gave me valuable hands-on experience applying AI techniques to real-world scenarios like optimization, search, game strategy, and agent design. Each task strengthened my understanding of how different algorithms perform under various conditions, constraints, and uncertainties.

## Demos
- [Go to Applications & Demos File](./applications-demos/) (Includes a more in-depth analysis of the programming assignments)  
- The feedback on the demos was very positive. For the demos that were graded, we received a perfect score. The only critique was that in one of the presentations, our speaking pace was a bit too fast.